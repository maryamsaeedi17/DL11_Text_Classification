{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh8zx_h3AsNo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iE6t-9BmBJL0"
      },
      "outputs": [],
      "source": [
        "def read_csv(file_path):\n",
        "  df = pd.read_csv(file_path)\n",
        "  X = np.array(df[\"sentence\"])\n",
        "  Y = np.array(df[\"label\"], dtype=int)\n",
        "\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1c9eT2E4B-dW"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = read_csv(\"/content/dataset/train.csv\")\n",
        "X_test, Y_test = read_csv(\"/content/dataset/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaYjMC6xCTGU",
        "outputId": "084bb600-4a66-410a-c0fe-e307e9530d1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('I love you mum', 0)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index = 5\n",
        "X_train[index], Y_train[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E4SxixiJCrCx"
      },
      "outputs": [],
      "source": [
        "def label_to_emoji(label):\n",
        "  emojies = [\"‚ù§Ô∏è\", \"‚öæÔ∏è\", \"üòÑ\", \"üòî\", \"üç¥\"]\n",
        "  return emojies[label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpBMOAHEu1nh",
        "outputId": "91fff532-88bd-4d07-de7e-38bc4b15f3f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('The chicago cubs won again', '‚öæÔ∏è')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index = 25\n",
        "X_train[index], label_to_emoji(Y_train[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiGvfPUkwBrb",
        "outputId": "9d056293-6fd0-4a88-c2a4-f005952b5832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4]\n",
            "[22 19 38 36 17]\n"
          ]
        }
      ],
      "source": [
        "unique, counts = np.unique(Y_train, return_counts=True)\n",
        "\n",
        "print(unique)\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDF17U8Cwo8m",
        "outputId": "eaa01563-d2e9-4f1a-cb45-b67d792a6ef3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len = len(max(X_train, key=len).split(\" \"))\n",
        "max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwsClzFiqdbe",
        "outputId": "dc954aac-ff51-4dba-a142-a4a2f2864b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-03 19:52:40--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-02-03 19:52:40--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‚Äòglove.6B.zip‚Äô\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2024-02-03 19:55:19 (5.18 MB/s) - ‚Äòglove.6B.zip‚Äô saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uAN9pqzOquu-"
      },
      "outputs": [],
      "source": [
        "!unzip -q glove.6B.zip -d glove.6B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vI3o6xSwsCQ0"
      },
      "outputs": [],
      "source": [
        "f = open(\"/content/glove.6B/glove.6B.50d.txt\", encoding=\"utf-8\")\n",
        "\n",
        "words_vector = {}\n",
        "for line in f:\n",
        "  line = line.strip().split()\n",
        "  word = line[0]\n",
        "  vector = np.array(line[1:], dtype=np.float64)\n",
        "  words_vector[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x6rmAyCt5DK",
        "outputId": "216eb1ea-07d8-47de-d3c8-850a61b612f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.49251 , -0.24279 , -0.49748 ,  0.28443 ,  0.16984 ,  0.61016 ,\n",
              "        0.20294 , -0.19734 ,  0.93474 , -0.11809 , -0.26342 ,  0.97142 ,\n",
              "        1.0427  ,  0.60017 , -0.46936 ,  0.10087 ,  0.60649 ,  1.1277  ,\n",
              "       -1.1823  , -0.29334 , -0.72885 , -0.46904 ,  1.1104  ,  0.27504 ,\n",
              "        0.48043 , -1.3031  , -0.58713 ,  0.90264 ,  0.089552, -0.60348 ,\n",
              "        1.1117  , -0.85367 , -0.13902 ,  0.87767 , -0.19307 ,  0.10299 ,\n",
              "       -0.83688 , -0.87202 ,  0.46529 , -0.22325 , -0.49207 ,  0.33727 ,\n",
              "       -0.49699 ,  0.95006 ,  0.75007 , -0.21252 ,  0.47244 , -1.4552  ,\n",
              "        0.11704 , -0.61483 ])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_vector[\"snake\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dddUFVhuBqS",
        "outputId": "41749795-dc83-4fb1-e0a5-e0c6c4c441a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.14957 , -0.16036 , -0.1369  ,  1.0076  , -0.37291 ,  0.63466 ,\n",
              "       -0.93203 , -1.5188  , -0.24924 ,  0.67075 ,  0.51193 ,  0.28389 ,\n",
              "        0.18781 ,  0.8798  , -0.023971,  0.39789 , -0.72769 ,  1.0153  ,\n",
              "        0.11723 , -0.14114 ,  0.974   ,  0.48037 ,  0.25464 ,  1.3262  ,\n",
              "        0.17958 ,  0.19717 ,  0.074712, -0.24844 ,  0.26248 , -0.084427,\n",
              "        3.156   ,  0.38308 , -0.095827, -0.99383 , -0.20497 ,  0.38918 ,\n",
              "       -0.13281 , -0.21775 , -0.93632 ,  0.37943 ,  0.78475 ,  0.36969 ,\n",
              "       -1.3904  ,  0.54891 , -1.3798  ,  0.18898 ,  0.60928 ,  0.98271 ,\n",
              "       -0.53934 ,  1.4439  ])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_vector[\"programming\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "kCxEyKu-ufWq"
      },
      "outputs": [],
      "source": [
        "def sentence_to_ave(sentence):\n",
        "  # try:\n",
        "  sentence = sentence.lower()\n",
        "  words = sentence.strip().split(\" \")\n",
        "\n",
        "  sum_vectors = np.zeros((50, ))\n",
        "  for word in words:\n",
        "    sum_vectors += words_vector[word]\n",
        "\n",
        "  ave_vector = sum_vectors / len(words)\n",
        "\n",
        "  return ave_vector\n",
        "  # except:\n",
        "  #   print(sentence)\n",
        "  #   return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkOnQ69Dv5fV",
        "outputId": "27c14f59-b599-4e89-c2b9-571f40d14aa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.157256  ,  0.1669862 , -0.188816  , -0.27733   ,  0.316686  ,\n",
              "        0.2276832 , -0.442016  , -0.19912792, -0.528786  ,  0.58095151,\n",
              "       -0.099434  ,  0.543644  , -0.400818  , -0.0196456 ,  0.6553478 ,\n",
              "        0.357032  ,  0.110736  ,  0.3904726 , -0.015683  , -0.5693798 ,\n",
              "       -0.11808   ,  0.662674  ,  0.50238   ,  0.380024  ,  0.798924  ,\n",
              "       -1.542946  , -0.8024376 ,  0.265944  ,  0.838432  , -0.497945  ,\n",
              "        3.32178   ,  0.516902  , -0.0628614 , -0.236668  , -0.1666506 ,\n",
              "       -0.104354  , -0.144238  ,  0.238698  , -0.116562  , -0.335334  ,\n",
              "        0.00965334,  0.2257584 , -0.261848  ,  0.44801   , -0.2448288 ,\n",
              "        0.1346956 ,  0.0192128 , -0.21776632, -0.28343   ,  0.698352  ])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_to_ave(\"I love programming too much\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC-2E2v9wU55",
        "outputId": "bc30f42b-8f32-46e6-b616-f1e7f7ce1a26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(132, 50)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_ave = []\n",
        "\n",
        "for x_train in X_train:\n",
        "  X_train_ave.append(sentence_to_ave(x_train))\n",
        "\n",
        "X_train_ave = np.array(X_train_ave)\n",
        "\n",
        "X_train_ave.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "YF-2kAJ5m8aL"
      },
      "outputs": [],
      "source": [
        "Y_train_one_hoted = tf.keras.utils.to_categorical(Y_train, num_classes=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "A8l0tv9wnmb0"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(5, input_shape=(50,), activation=\"Softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "cpzNVhSPoVYb"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEdkdKz_pb3i",
        "outputId": "74f48397-1445-41e9-cb5c-4630804294f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7913 - accuracy: 0.7576\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7902 - accuracy: 0.7652\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7886 - accuracy: 0.7652\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7869 - accuracy: 0.7727\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7853 - accuracy: 0.7727\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7833 - accuracy: 0.7652\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7815 - accuracy: 0.7652\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7797 - accuracy: 0.7652\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7786 - accuracy: 0.7652\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7767 - accuracy: 0.7727\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7749 - accuracy: 0.7652\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7730 - accuracy: 0.7652\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7714 - accuracy: 0.7652\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7694 - accuracy: 0.7652\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7680 - accuracy: 0.7652\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7663 - accuracy: 0.7576\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7644 - accuracy: 0.7500\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7631 - accuracy: 0.7576\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7613 - accuracy: 0.7576\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7596 - accuracy: 0.7576\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7584 - accuracy: 0.7652\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7571 - accuracy: 0.7576\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7550 - accuracy: 0.7652\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7535 - accuracy: 0.7652\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7517 - accuracy: 0.7652\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7504 - accuracy: 0.7652\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7492 - accuracy: 0.7652\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7475 - accuracy: 0.7652\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7460 - accuracy: 0.7727\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7443 - accuracy: 0.7652\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7429 - accuracy: 0.7652\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7413 - accuracy: 0.7727\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7400 - accuracy: 0.7727\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7384 - accuracy: 0.7727\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7373 - accuracy: 0.7803\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7358 - accuracy: 0.7803\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7344 - accuracy: 0.7727\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7328 - accuracy: 0.7652\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7314 - accuracy: 0.7652\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7297 - accuracy: 0.7727\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7282 - accuracy: 0.7879\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7268 - accuracy: 0.7879\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7254 - accuracy: 0.7879\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7234 - accuracy: 0.7879\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7223 - accuracy: 0.7803\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7214 - accuracy: 0.7727\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7196 - accuracy: 0.7803\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7188 - accuracy: 0.7803\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7178 - accuracy: 0.7955\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7169 - accuracy: 0.7955\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7156 - accuracy: 0.7955\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7143 - accuracy: 0.7955\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7132 - accuracy: 0.7955\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7120 - accuracy: 0.7879\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7100 - accuracy: 0.7879\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7084 - accuracy: 0.7879\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7072 - accuracy: 0.7879\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7058 - accuracy: 0.7955\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7047 - accuracy: 0.7955\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7031 - accuracy: 0.7955\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.8030\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.8030\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6990 - accuracy: 0.7879\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.7879\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6965 - accuracy: 0.7955\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.7955\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.8030\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.8030\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6921 - accuracy: 0.7955\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6907 - accuracy: 0.8030\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.8030\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6880 - accuracy: 0.8030\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6869 - accuracy: 0.8030\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.7955\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.7879\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.7879\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6818 - accuracy: 0.8030\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6807 - accuracy: 0.8030\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.8030\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6783 - accuracy: 0.7955\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6770 - accuracy: 0.8030\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6759 - accuracy: 0.7955\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6747 - accuracy: 0.7955\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.8030\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6729 - accuracy: 0.8030\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6717 - accuracy: 0.8030\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6716 - accuracy: 0.8030\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6707 - accuracy: 0.8030\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6694 - accuracy: 0.8030\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6682 - accuracy: 0.8106\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6668 - accuracy: 0.8106\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6655 - accuracy: 0.8106\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6641 - accuracy: 0.8106\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.8106\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6617 - accuracy: 0.8106\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6603 - accuracy: 0.8106\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6595 - accuracy: 0.8106\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.8106\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6570 - accuracy: 0.8106\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6557 - accuracy: 0.8258\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.8258\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6534 - accuracy: 0.8258\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6524 - accuracy: 0.8258\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6514 - accuracy: 0.8258\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6503 - accuracy: 0.8258\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6494 - accuracy: 0.8182\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.8182\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.8333\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6464 - accuracy: 0.8258\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6453 - accuracy: 0.8182\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6442 - accuracy: 0.8182\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6434 - accuracy: 0.8182\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6427 - accuracy: 0.8182\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.8182\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6406 - accuracy: 0.8182\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6396 - accuracy: 0.8182\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.8106\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6382 - accuracy: 0.8182\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6370 - accuracy: 0.8182\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.8258\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6356 - accuracy: 0.8182\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.8182\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.8258\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6325 - accuracy: 0.8258\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6312 - accuracy: 0.8106\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.8106\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6285 - accuracy: 0.8182\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6273 - accuracy: 0.8182\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6263 - accuracy: 0.8258\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6252 - accuracy: 0.8333\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6243 - accuracy: 0.8409\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6233 - accuracy: 0.8409\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.8409\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.8485\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6203 - accuracy: 0.8409\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.8409\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.8409\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.8409\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.8409\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6175 - accuracy: 0.8409\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6164 - accuracy: 0.8333\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6155 - accuracy: 0.8333\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6147 - accuracy: 0.8409\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6137 - accuracy: 0.8409\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.8333\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6118 - accuracy: 0.8333\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6106 - accuracy: 0.8333\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6097 - accuracy: 0.8333\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.8333\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6071 - accuracy: 0.8409\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6064 - accuracy: 0.8409\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6053 - accuracy: 0.8409\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6046 - accuracy: 0.8409\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6037 - accuracy: 0.8409\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6029 - accuracy: 0.8409\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6016 - accuracy: 0.8561\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6009 - accuracy: 0.8485\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6000 - accuracy: 0.8409\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5991 - accuracy: 0.8409\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5986 - accuracy: 0.8409\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5979 - accuracy: 0.8333\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5967 - accuracy: 0.8333\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.8409\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5955 - accuracy: 0.8485\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5945 - accuracy: 0.8485\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.8485\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5935 - accuracy: 0.8485\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5930 - accuracy: 0.8409\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5921 - accuracy: 0.8409\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5911 - accuracy: 0.8409\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.8409\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.8409\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5875 - accuracy: 0.8485\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.8485\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.8561\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5856 - accuracy: 0.8561\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.8485\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5837 - accuracy: 0.8561\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.8561\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.8561\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5812 - accuracy: 0.8561\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.8561\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5793 - accuracy: 0.8636\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5786 - accuracy: 0.8561\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.5775 - accuracy: 0.8485\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5766 - accuracy: 0.8485\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5760 - accuracy: 0.8561\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5749 - accuracy: 0.8561\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.8561\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5736 - accuracy: 0.8561\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.8561\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5723 - accuracy: 0.8561\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5715 - accuracy: 0.8561\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5705 - accuracy: 0.8561\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.8561\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5688 - accuracy: 0.8636\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5681 - accuracy: 0.8636\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5673 - accuracy: 0.8636\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5665 - accuracy: 0.8636\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5658 - accuracy: 0.8636\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c7ccd7915a0>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_ave, Y_train_one_hoted, epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQqjOH0dpx-S",
        "outputId": "e3c9e781-342e-4e2f-9c72-ed734c5faa75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.19149   ,  0.39613   , -0.29437825, -0.45514   ,  0.58745   ,\n",
              "       -0.1885175 , -0.4617425 , -0.1886249 , -0.0073275 ,  0.25208964,\n",
              "       -0.0832225 ,  0.599987  , -0.2566225 , -0.22175525,  0.995455  ,\n",
              "        0.4280425 ,  0.1588746 ,  0.07874   ,  0.100787  , -0.52995725,\n",
              "       -0.06616   ,  0.483167  ,  0.57353   ,  0.3309475 ,  0.672675  ,\n",
              "       -1.651235  , -1.045405  ,  0.13963   ,  0.9171275 , -0.46865   ,\n",
              "        3.20685   ,  0.6419725 , -0.4071875 ,  0.08056   , -0.215035  ,\n",
              "       -0.0615625 , -0.0311025 ,  0.1012125 ,  0.389025  , -0.22      ,\n",
              "       -0.07731833,  0.165113  ,  0.0754775 ,  0.159702  ,  0.4388465 ,\n",
              "        0.41323   , -0.135089  , -0.46333   , -0.0194825 ,  0.428735  ])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_test_sentence = \"I love see food\"\n",
        "\n",
        "my_test_ave = sentence_to_ave(my_test_sentence)\n",
        "my_test_ave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKn2-TKeqvPx",
        "outputId": "d073a346-be4e-46b8-8c19-68e264a6277d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_test_ave = np.array([my_test_ave])\n",
        "\n",
        "result = model.predict(my_test_ave)\n",
        "y_pred = np.argmax(result)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jJ8irTRArVV1",
        "outputId": "10530247-d530-4c34-f17e-ef3e28b802f3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'üç¥'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_to_emoji(y_pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
